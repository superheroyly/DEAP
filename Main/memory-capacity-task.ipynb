{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Leaky integrator model of Echo State Network\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_NODES = 200\n",
    "SPECT_RADIUS = 0.9\n",
    "W_IN = (np.random.rand(N_NODES, 1) * 2 - 1)*0.1\n",
    "a = 1\n",
    "time_scale = np.ones(N_NODES)*a\n",
    "trainlen = 5000\n",
    "future = 1000\n",
    "buffer = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def correct_dimensions(s, targetlength):\n",
    "    if s is not None:\n",
    "        s = np.array(s)\n",
    "        if s.ndim == 0:\n",
    "            s = np.array([s] * targetlength)\n",
    "        elif s.ndim == 1:\n",
    "            if not len(s) == targetlength:\n",
    "                raise ValueError(\"arg must have length \" + str(targetlength))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid argument\")\n",
    "    return s\n",
    "\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-10*x+1))\n",
    "\n",
    "\n",
    "class LI_ESN_internal:\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, n_reservoir=200, W=None, W_in=None,\n",
    "                 noise=0.001, input_shift=None,\n",
    "                 input_scaling=None, feedback_scaling=None,\n",
    "                 teacher_scaling=None, teacher_shift=None,\n",
    "                 out_activation=identity, inverse_out_activation=identity,\n",
    "                 random_state=None, time_scale=None):\n",
    "        # check for proper dimensionality of all arguments and write them down.\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_reservoir = n_reservoir\n",
    "        self.n_outputs = n_outputs\n",
    "        self.noise = noise\n",
    "        self.input_shift = correct_dimensions(input_shift, n_inputs)\n",
    "        self.input_scaling = correct_dimensions(input_scaling, n_inputs)\n",
    "\n",
    "        self.teacher_scaling = teacher_scaling\n",
    "        self.teacher_shift = teacher_shift\n",
    "\n",
    "        self.out_activation = out_activation\n",
    "        self.inverse_out_activation = inverse_out_activation\n",
    "        self.random_state = random_state\n",
    "        self.time_scale = time_scale\n",
    "        self.W = W\n",
    "        self.W_in = W_in\n",
    "        print(1111)\n",
    "        # the given random_state might be either an actual RandomState object,\n",
    "        # a seed or None (in which case we use numpy's builtin RandomState)\n",
    "        if isinstance(random_state, np.random.RandomState):\n",
    "            self.random_state_ = random_state\n",
    "        elif random_state:\n",
    "            try:\n",
    "                self.random_state_ = np.random.RandomState(random_state)\n",
    "            except TypeError as e:\n",
    "                raise Exception(\"Invalid seed: \" + str(e))\n",
    "        else:\n",
    "            self.random_state_ = np.random.mtrand._rand\n",
    "\n",
    "    def _update(self, state, input_pattern):\n",
    "        # leaky integrator model:\n",
    "        # it can adjust timescales for each neurons.\n",
    "        preactivation = (np.dot(self.W, state) + np.dot(self.W_in, input_pattern))\n",
    "        state = (1 - self.time_scale) * state + self.time_scale * np.tanh(preactivation)\n",
    "        return (state + self.noise * self.time_scale * (self.random_state_.rand(self.n_reservoir) - 0.5))\n",
    "\n",
    "    def calc_lyapunov_exp(self, inputs, initial_distance, n):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        states1 = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        states2 = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        transient = min(int(inputs.shape[0] / 10), 100)\n",
    "        for i in range(1, transient):\n",
    "            states1[i, :] = self._update(states1[i-1], inputs[i, :])\n",
    "        states2[transient-1, :] = states1[transient-1, :]\n",
    "        states2[transient-1, n] = states2[transient-1, n] + initial_distance\n",
    "        gamma_k_list = []\n",
    "        for k in range(transient, inputs.shape[0]):\n",
    "            states1[k, :] = self._update(states1[k-1], inputs[k, :])\n",
    "            states2[k, :] = self._update(states2[k-1], inputs[k, :])\n",
    "            gamma_k = np.linalg.norm(states2[k, :]-states1[k, :])\n",
    "            gamma_k_list.append(gamma_k/initial_distance)\n",
    "            states2[k, :] = states1[k, :] + (initial_distance/gamma_k)*(states2[k, :]-states1[k, :])\n",
    "        lyapunov_exp = np.mean(np.log(gamma_k_list))\n",
    "        return lyapunov_exp\n",
    "            \n",
    "    \n",
    "    def fit(self, inputs, outputs):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        if outputs.ndim < 2:\n",
    "            outputs = np.reshape(outputs, (len(outputs), -1))\n",
    "        inputs_scaled = inputs\n",
    "        teachers_scaled = outputs\n",
    "\n",
    "        # step the reservoir through the given input,output pairs:\n",
    "        states = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        for n in range(1, inputs.shape[0]):\n",
    "            states[n, :] = self._update(states[n - 1], inputs_scaled[n, :])\n",
    "        transient = min(int(inputs.shape[0] / 10), 100)\n",
    "        \n",
    "        self.W_out = np.dot(np.linalg.pinv(states[transient:, :]),teachers_scaled[transient:, :]).T\n",
    "\n",
    "        # remember the last state for later:\n",
    "        self.laststate = states[-1, :]\n",
    "        self.lastinput = inputs[-1, :]\n",
    "        self.lastoutput = teachers_scaled[-1, :]\n",
    "            \n",
    "        # apply learned weights to the collected states:\n",
    "        pred_train = np.dot(states[:, :], self.W_out.T)\n",
    "        return pred_train\n",
    "\n",
    "    def predict(self, inputs, continuation=True):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        if continuation:\n",
    "            laststate = self.laststate\n",
    "            lastinput = self.lastinput\n",
    "            lastoutput = self.lastoutput\n",
    "        else:\n",
    "            laststate = np.zeros(self.n_reservoir)\n",
    "            lastinput = np.zeros(self.n_inputs)\n",
    "            lastoutput = np.zeros(self.n_outputs)\n",
    "\n",
    "        inputs = np.vstack([lastinput, inputs])\n",
    "        states = np.vstack(\n",
    "            [laststate, np.zeros((n_samples, self.n_reservoir))])\n",
    "        outputs = np.vstack(\n",
    "            [lastoutput, np.zeros((n_samples, self.n_outputs))])\n",
    "\n",
    "        for n in range(n_samples):\n",
    "            states[n + 1, :] = self._update(states[n, :], inputs[n + 1, :])\n",
    "            outputs[n + 1, :] = np.dot(self.W_out,states[n + 1, :])\n",
    "\n",
    "        return self.out_activation(outputs[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def correct_dimensions(s, targetlength):\n",
    "    if s is not None:\n",
    "        s = np.array(s)\n",
    "        if s.ndim == 0:\n",
    "            s = np.array([s] * targetlength)\n",
    "        elif s.ndim == 1:\n",
    "            if not len(s) == targetlength:\n",
    "                raise ValueError(\"arg must have length \" + str(targetlength))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid argument\")\n",
    "    return s\n",
    "\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "class LI_ESN_internal:\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, n_reservoir=200, W=None, W_in=None,\n",
    "                 noise=0.001, input_shift=None,\n",
    "                 input_scaling=None, feedback_scaling=None,\n",
    "                 teacher_scaling=None, teacher_shift=None,\n",
    "                 out_activation=identity, inverse_out_activation=identity,\n",
    "                 random_state=None, time_scale=None):\n",
    "        # check for proper dimensionality of all arguments and write them down.\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_reservoir = n_reservoir\n",
    "        self.n_outputs = n_outputs\n",
    "        self.noise = noise\n",
    "        self.input_shift = correct_dimensions(input_shift, n_inputs)\n",
    "        self.input_scaling = correct_dimensions(input_scaling, n_inputs)\n",
    "\n",
    "        self.teacher_scaling = teacher_scaling\n",
    "        self.teacher_shift = teacher_shift\n",
    "\n",
    "        self.out_activation = out_activation\n",
    "        self.inverse_out_activation = inverse_out_activation\n",
    "        self.random_state = random_state\n",
    "        self.time_scale = time_scale\n",
    "        self.W = W\n",
    "        self.W_in = W_in\n",
    "        print(222)\n",
    "        # the given random_state might be either an actual RandomState object,\n",
    "        # a seed or None (in which case we use numpy's builtin RandomState)\n",
    "        if isinstance(random_state, np.random.RandomState):\n",
    "            self.random_state_ = random_state\n",
    "        elif random_state:\n",
    "            try:\n",
    "                self.random_state_ = np.random.RandomState(random_state)\n",
    "            except TypeError as e:\n",
    "                raise Exception(\"Invalid seed: \" + str(e))\n",
    "        else:\n",
    "            self.random_state_ = np.random.mtrand._rand\n",
    "            \n",
    "    def _scale_inputs(self, inputs):\n",
    "        \"\"\"for each input dimension j: multiplies by the j'th entry in the\n",
    "        input_scaling argument, then adds the j'th entry of the input_shift\n",
    "        argument.\"\"\"\n",
    "        if self.input_scaling is not None:\n",
    "            inputs = np.dot(inputs, np.diag(self.input_scaling))\n",
    "        if self.input_shift is not None:\n",
    "            inputs = inputs + self.input_shift\n",
    "        return inputs\n",
    "\n",
    "    def _update(self, state, input_pattern):\n",
    "        # leaky integrator model:\n",
    "        # it can adjust timescales for each neurons.\n",
    "        preactivation = (np.dot(self.W, state) + np.dot(self.W_in, input_pattern))\n",
    "        # state = (1 - self.time_scale) * state + self.time_scale * np.tanh(preactivation)\n",
    "        state = (1 - self.time_scale) * state + self.time_scale * sigmoid(preactivation)\n",
    "        return (state + self.noise * self.time_scale * (self.random_state_.rand(self.n_reservoir) - 0.5))\n",
    "\n",
    "    def calc_lyapunov_exp(self, inputs, initial_distance, n):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        states1 = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        states2 = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        transient = min(int(inputs.shape[0] / 10), 100)\n",
    "        for i in range(1, transient):\n",
    "            states1[i, :] = self._update(states1[i-1], inputs[i, :])\n",
    "        states2[transient-1, :] = states1[transient-1, :]\n",
    "        states2[transient-1, n] = states2[transient-1, n] + initial_distance\n",
    "        gamma_k_list = []\n",
    "        for k in range(transient, inputs.shape[0]):\n",
    "            states1[k, :] = self._update(states1[k-1], inputs[k, :])\n",
    "            states2[k, :] = self._update(states2[k-1], inputs[k, :])\n",
    "            gamma_k = np.linalg.norm(states2[k, :]-states1[k, :])\n",
    "            gamma_k_list.append(gamma_k/initial_distance)\n",
    "            states2[k, :] = states1[k, :] + (initial_distance/gamma_k)*(states2[k, :]-states1[k, :])\n",
    "        lyapunov_exp = np.mean(np.log(gamma_k_list))\n",
    "        return lyapunov_exp\n",
    "            \n",
    "    \n",
    "    def fit(self, inputs, outputs):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        if outputs.ndim < 2:\n",
    "            outputs = np.reshape(outputs, (len(outputs), -1))\n",
    "        inputs_scaled = self._scale_inputs(inputs)\n",
    "        teachers_scaled = outputs\n",
    "\n",
    "        # step the reservoir through the given input,output pairs:\n",
    "        states = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        for n in range(1, inputs.shape[0]):\n",
    "            states[n, :] = self._update(states[n - 1], inputs_scaled[n, :])\n",
    "        transient = min(int(inputs.shape[0] / 10), 100)\n",
    "        extended_states = np.hstack((states, inputs_scaled))\n",
    "        \n",
    "        self.W_out = np.dot(np.linalg.pinv(extended_states[transient:, :]),teachers_scaled[transient:, :]).T\n",
    "        # print(self.W_out.shape)\n",
    "\n",
    "        # remember the last state for later:\n",
    "        self.laststate = states[-1, :]\n",
    "        self.lastinput = inputs[-1, :]\n",
    "        self.lastoutput = teachers_scaled[-1, :]\n",
    "            \n",
    "        # apply learned weights to the collected states:\n",
    "        pred_train = np.dot(extended_states, self.W_out.T)\n",
    "        return pred_train\n",
    "\n",
    "    def predict(self, inputs, continuation=True):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        if continuation:\n",
    "            laststate = self.laststate\n",
    "            lastinput = self.lastinput\n",
    "            lastoutput = self.lastoutput\n",
    "        else:\n",
    "            laststate = np.zeros(self.n_reservoir)\n",
    "            lastinput = np.zeros(self.n_inputs)\n",
    "            lastoutput = np.zeros(self.n_outputs)\n",
    "\n",
    "        inputs = np.vstack([lastinput, inputs])\n",
    "        states = np.vstack(\n",
    "            [laststate, np.zeros((n_samples, self.n_reservoir))])\n",
    "        outputs = np.vstack(\n",
    "            [lastoutput, np.zeros((n_samples, self.n_outputs))])\n",
    "\n",
    "        for n in range(n_samples):\n",
    "            states[n + 1, :] = self._update(states[n, :], inputs[n + 1, :])\n",
    "            outputs[n + 1, :] = np.dot(self.W_out,np.concatenate([states[n + 1, :], inputs[n + 1, :]]))\n",
    "\n",
    "        return self.out_activation(outputs[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def memory_capacity(L, buffer, data, output_data):\n",
    "    MC = 0\n",
    "    for k in range(L):\n",
    "        cov_matrix = np.cov(np.array([data[trainlen+buffer-(k+1): trainlen+buffer-(k+1)+1000],output_data.T[k]]))\n",
    "        MC_k = cov_matrix[0][1]**2\n",
    "        MC_k = MC_k / (np.var(data[trainlen+buffer:])*np.var(output_data.T[k]))\n",
    "        MC += MC_k\n",
    "    return MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from make_modular_networks import make_modular_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8999999999999996\n",
      "0.8999999999999996\n"
     ]
    }
   ],
   "source": [
    "W = make_modular_network(N_NODES, 6, 50, 0.0)\n",
    "W_tilda = (1-a)*np.eye(N_NODES) + a*W\n",
    "radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "radius_tilda = np.max(np.abs(np.linalg.eigvals(W_tilda)))\n",
    "# print(radius, radius_tilda)\n",
    "spectral_radius = SPECT_RADIUS\n",
    "W = W * (spectral_radius / radius)\n",
    "W_tilda = (1-a)*np.eye(N_NODES) + a*W\n",
    "# W_tilda = W_tilda * (spectral_radius / radius_tilda)\n",
    "# W = (1/a)*(W_tilda - (1-a)*np.eye(N_NODES))\n",
    "radius_tilda = np.max(np.abs(np.linalg.eigvals(W_tilda)))\n",
    "print(radius_tilda)\n",
    "\n",
    "radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "print(radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n",
      "20.041579465276804\n"
     ]
    }
   ],
   "source": [
    "# delayed signal\n",
    "# L = int(N_NODES*2)\n",
    "L = 20\n",
    "\n",
    "buffer = L\n",
    "total_len = future + trainlen + buffer\n",
    "tau = 0.3\n",
    "data = (np.random.rand(total_len)*2-1)*tau\n",
    "\n",
    "\n",
    "esn = LI_ESN_internal(n_inputs=1,\n",
    "                      n_outputs=L,\n",
    "                      n_reservoir=N_NODES,\n",
    "                      W=W,\n",
    "                      W_in=W_IN,\n",
    "                      noise=0,\n",
    "                      time_scale=time_scale)\n",
    "\n",
    "\n",
    "target = np.zeros((total_len - buffer, L))\n",
    "for i in range(L):\n",
    "    target.T[i][:] = data[buffer-(i+1):-(i+1)]\n",
    "\n",
    "pred_training = esn.fit(data[buffer:trainlen+buffer], target[:trainlen])\n",
    "\n",
    "prediction = esn.predict(data[trainlen+buffer:])\n",
    "\n",
    "\n",
    "    \n",
    "print(memory_capacity(L, buffer, data, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 222\n",
    "# 18.399776171814448\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}